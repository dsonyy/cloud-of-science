<h1>Głębokie uczenie maszynowe</h1>
<h3>Intro</h3>
<p>
Komputery były początkowo „maszynami programowalnymi”, których algorytmy były pieczołowicie projektowane, komenda po komendzie. Jeden z wielkich geniuszów i wizjonerów XX-wiecznej informatyki, 
Alan Turing, już w  1950 roku zaproponował model komputera, który 
samodzielnie generuje algorytmy, ucząc się na swoich błędach i sukcesach. W II połowie XX wieku program ten był stopniowo rozwijany, ale 
dopiero w XXI wieku udało się przemienić go w skuteczne narzędzie, bę-dące jednym z fundamentów programowania. Uczenie przez wzmacnianie jest, nawiasem mówiąc, jedną z gałęzi uczenia maszynowego(machine learning). Termin ów, który będzie regularnym gościem na kartach 
tej książki, obejmuje wszystkie przypadki, gdy algorytmy komputerowe 
automatycznie stają się coraz skuteczniejsze wskutek nabierania „do-świadczenia” i analizy danych.
</p>

<p>
  "Połącz kropki", str. 25.
</p>

<p>
  Podstawowe pojęcia, których używamy dzisiaj, mówiąc o "sztucznej inteligencji" - jak "sieci neuronowe" czy "uczenie maszynowe" - mają długą historią. W XXI wieku coraz częściej dodaje się do nich epitet "głęboki". Czysto technicznie, ma on związek z liczbą "warstw", z których zbudowany jest dany algorytm. W parze z czysto ilościowym wzrostem - więcej bramek logicznych, więcej zmiennych, więcej neuronów - idzie też rosnąca komplikacja jakościowa. Z tą zaś - rosnąca "inteligencja"...
</p>
<h3>Poczytaj więcej</h3>
<p><u>Ramki w książce na ten temat</u>: <b>AI Dungeon</b>, <b>Project Debater, czyli jak się pokłócić z komputerem</b>, <b>Konwolucyjne sieci neuronowe</b>, <b>Generatywne sieci adwersarialne</b>, <b>Pijana kobieta podnosi ciężary</b>
</p>
<h3>Zobacz więcej</h3>
<p>W "Czytamy naturę" opowiadałem kiedyś o bardzo ciekawym zastosowaniu dla przygotowanego przez IBM "koktajlu" głębokich sieci neuronowych:</p>
<p>
  <iframe
	width="450"
	height="280"
	src="https://www.youtube.com/watch?v=G1tpPs__Y7I&t=683s"
	frameborder="0"
	allowfullscreen
  ></iframe>
</p>